{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 数据小白入门教程\n",
    "\n",
    "数据小白入门教程主要通过阿里天池平台的新手入门赛中的[阿里移动推荐算法](https://tianchi.shuju.aliyun.com/getStart/introduction.htm?spm=5176.100066.333.3.iY9ga2&raceId=231522)为基本案例，来阐述怎样使用数据取解决问题或者参加比赛，若大家进一步对数据分析或挖掘比较感兴趣，可以参看阿里天池[新手入门视频](https://tianchi.shuju.aliyun.com/video.htm?spm=5176.100067.1234.7.3hqMDK)学习，同时可以通过[比赛](https://tianchi.shuju.aliyun.com/competition/index.htm?spm=5176.7953375.1234.2.tqpeV8&id=)去强化技术水平。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 赛题解读\n",
    "\n",
    "### 1. 干啥的\n",
    "\n",
    "根据用户在手机淘宝上的历史行为数据，预测用户们第二天买了什么\n",
    "\n",
    "1. 历史行为记录是什么？\n",
    "\n",
    "谁在什么时间对某一物品干啥了。\n",
    "\n",
    "2. 到底预测的是什么？\n",
    "\n",
    "在第32天中，谁买了什么。\n",
    "\n",
    "### 2. 咋评价\n",
    "\n",
    "如果比预测的多：那么提交所有种可能，必得满分\n",
    "\n",
    "如果比预测的准：只预测一条对的，必得满分\n",
    "\n",
    "因此评价指标必须要兼顾到“多”和“准”\n",
    "\n",
    "--------\n",
    "例子\n",
    "\n",
    "假设第31天(12月19号)发生了20000次交易，我们预测了10000条，预测对了1000条\n",
    "\n",
    "准确率： 1000/10000 = 0.1\n",
    "召回率： 1000/20000 = 0.05\n",
    "\n",
    "F1 = 2 * 0.1 * 0.05 / (0.1 + 0.05)\n",
    "\n",
    "\n",
    "### 3. 咋做\n",
    "\n",
    "我们先从业务常识去判断，什么样的user-item pair，可能在下一天中发生\"购买\"：\n",
    "\n",
    "1. 用户i不停的去看商品j, 预测: $user_i-item_j$\n",
    "\n",
    "2. 用户i将商品j放入购物车，预测: $user_i-item_j$\n",
    "\n",
    "3. 用户i非常喜欢买东西，预测和$user_i$相关的所有pair\n",
    "\n",
    "4. 商品j这几天卖得很好，预测和$item_j$相关的所有pair\n",
    "\n",
    "\n",
    "### 4. 咋做好\n",
    "\n",
    "如何将多个规则结合在一起：\n",
    "\n",
    "1. 按照每一个规则是否达标进行打分，打分最高的当作预测\n",
    "\n",
    "2. 自动的确定分数: Logistics Regression\n",
    "\n",
    "3. 如果诸多规则和目标之间的关系是非线性的咋办： More Machine Learning Algorithm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 数据处理\n",
    "\n",
    "### 1. 移动端行为数据加载到MySQL\n",
    "\n",
    "#### 1.1建表\n",
    "\n",
    "```sql\n",
    "\n",
    "CREATE TABLE IF NOT EXISTS mobile_recomm_user_log_2w (\n",
    "    `user_id` varchar(255) DEFAULT NULL,\n",
    "    `item_id` varchar(255) DEFAULT NULL,\n",
    "    `behavior_type` int(4) DEFAULT 0,\n",
    "    `user_geohash` varchar(255) DEFAULT NULL,\n",
    "    `date` DATE,\n",
    "    `time` int(4)\n",
    ") ENGINE=MyISAM DEFAULT CHARSET=utf8;\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/EricDoug/Documents/myDevelopment/dataMaker/tutorial\n",
      "{'passwd': '123456', 'host': 'localhost', 'db': 'tutorial', 'port': 3306, 'user': 'root'}\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "datamaker_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "sys.path.insert(0, datamaker_root + 'tutorial')\n",
    "\n",
    "import os\n",
    "\n",
    "print os.getcwd()\n",
    "\n",
    "from mysql_helper import MySQLHelper\n",
    "from config_helper import Config_Read\n",
    "\n",
    "creat_table_sql = \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS mobile_recomm_user_log_2w (\n",
    "    `user_id` varchar(255) DEFAULT NULL,\n",
    "    `item_id` varchar(255) DEFAULT NULL,\n",
    "    `behavior_type` int(4) DEFAULT 0,\n",
    "    `user_geohash` varchar(255) DEFAULT NULL,\n",
    "    `dt` DATE,\n",
    "    `time` int(4)\n",
    ") ENGINE=MyISAM DEFAULT CHARSET=utf8;\n",
    "\"\"\"\n",
    "# 获取MySQL配置信息\n",
    "mysql_info = Config_Read('mysql')._get_config_info\n",
    "print mysql_info\n",
    "\n",
    "# 连接MySQL \n",
    "mysqler = MySQLHelper(mysql_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建表\n",
    "mysqler.execute(creat_table_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "#### 1.2 数据加载到MySQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_id,item_id,behavior_type,user_geohash,item_category,time\r\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "data_dir = \"/Users/EricDoug/Documents/datas/ali/fresh_comp_offline\"\n",
    "file_name = \"tianchi_fresh_comp_train_user.csv\"\n",
    "train_data = os.path.join(data_dir,file_name)\n",
    "\n",
    "\n",
    "# 按行加载数据到MySQL\n",
    "\n",
    "with open(train_data) as f:\n",
    "    # read header\n",
    "    header = f.readline()\n",
    "    print header\n",
    "    rows = f.readlines()\n",
    "    # 统计加载数据时间\n",
    "    start_time = datetime.datetime.now()\n",
    "    for row in rows:\n",
    "        # 去空白\n",
    "        row = row.strip()\n",
    "        # 使用“,”wei提取\n",
    "        cols = row.split(',')\n",
    "        user_id = cols[0]\n",
    "        item_id = cols[1]\n",
    "        behavior_type = cols[2]\n",
    "        user_geohash = cols[3]\n",
    "        item_category = cols[4]\n",
    "        dtime= cols[5]\n",
    "        date_time = dtime.split(' ')\n",
    "        dt = date_time[0]\n",
    "        time = date_time[1]\n",
    "        #print user_id, item_id, dt, time\n",
    "        insert_sql_str = \"INSERT INTO mobile_recomm_user_log_2w(user_id, item_id, behavior_type, user_geohash, dt, time)  \\\n",
    "                 VALUES ('%s', '%s', %s, '%s', '%s' , %s)\"\n",
    "        \n",
    "        insert_sql = insert_sql_str % (user_id, item_id, behavior_type, user_geohash, dt, time)\n",
    "        #print insert_sql\n",
    "        # 按行插入2万行\n",
    "        mysqler.execute(insert_sql)\n",
    "        \n",
    "    end_time = datetime.datetime.now()\n",
    "    print \"load data spend:\" (end_time - start_time).seconds \n",
    "        \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 特征提取\n",
    "\n",
    "赛题给的是2014年11月18日到2014年12月18日，需要预测2014年12月19日这一天用户的购买。为了有效对模型进行评估，我们必须划分一个离线的模型校验数据集，使用12月18日的数据为测试数据集，将11月18日到12月17日的数据用于模型训练。由于一个月时间的用户行为大致为2000万条记录，使用所有数据计算量有点大，为了减少计算量，我们采用预测前一周的用户行为进行模型训练，下面主要使用一周的数据构建特征(若机器性能允许，可以考虑使用一个月数据)。\n",
    "\n",
    "### 1. 该用户是否会周期性购买某一物品\n",
    "\n",
    "1.前1天(12月17日)是否购买，购买为1， 没有购买为0\n",
    "2.前2天(12月16日)是否购买，购买为1， 没有购买为0\n",
    "3.前3天(12月15日)是否购买，购买为1， 没有购买为0\n",
    "4.前4天(12月14日)是否购买，购买为1， 没有购买为0\n",
    "5.前5天(12月13日)是否购买，购买为1， 没有购买为0\n",
    "6.前6天(12月12日)是否购买，购买为1， 没有购买为0\n",
    "7.前7天(12月11日)是否购买，购买为1， 没有购买为0\n",
    "\n",
    "```sql\n",
    "    SELECT ui.user_id, ui.item_id,\n",
    "    IF(buy_1.user_id = NULL,0,1) \n",
    "    FROM \n",
    "    (SELECT user_id, item_id FROM mobile_recomm_user_log_2w WHERE dt BETWEEN '2014-12-11'\n",
    "    AND '2014-12-17' group by user_id,item_id) AS ui\n",
    "    LEFT JOIN\n",
    "    (SELECT user_id, item_id FROM mobile_recomm_user_log_2w WHERE dt = '2014-12-17') buy_1\n",
    "    ON ui.user_id = buy_1.user_id and ui.item_id = buy_1.item_id\n",
    "    \n",
    "\n",
    "```\n",
    "\n",
    "### 2. 加入购物车与购买的关系\n",
    "\n",
    "8前1天内(12月17)加入购物车的次数\n",
    "9.前2天内(12.16~12.17)加入购物车的次数\n",
    "10.前3天内(12.15~12.17)加入购物车的次数\n",
    "11.前5天内(12.13~12.17)加入购物车的次数\n",
    "12.前7天内(12.11~12.17)加入购物车的次数\n",
    "\n",
    "### 3. 收藏与购买的关系\n",
    "13.前1天内(12月17)加入收藏的次数\n",
    "14.前2天内(12.16~12.17)加入收藏的次数\n",
    "15.前3天内(12.15~12.17)加入收藏的次数\n",
    "16.前5天内(12.13~12.17)加入收藏的次数\n",
    "17.前7天内(12.11~12.17)加入收藏的次数\n",
    "\n",
    "### 4. 浏览与购买的关系\n",
    "\n",
    "18.前1天内(12月17)加入浏览的次数\n",
    "19.前2天内(12.16~12.17)加入浏览的次数\n",
    "20.前3天内(12.15~12.17)加入浏览的次数\n",
    "21.前5天内(12.13~12.17)加入浏览的次数\n",
    "22.前7天内(12.11~12.17)加入浏览的次数\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 构建模型\n",
    "\n",
    "### 1. Logister Regression\n",
    "\n",
    "\n",
    "##### 1.1 Sklearn实现\n",
    "\n",
    "#### 1.2 Tensorflow 实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 模型验证"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
